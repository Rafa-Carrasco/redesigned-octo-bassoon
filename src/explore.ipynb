{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your code here\n",
                "import os\n",
                "import pandas as pd\n",
                "import requests\n",
                "import matplotlib.pyplot as plt \n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# 1. descargar data\n",
                "\n",
                "# url = \"https://raw.githubusercontent.com/4GeeksAcademy/logistic-regression-project-tutorial/main/bank-marketing-campaign-data.csv\"\n",
                "# respuesta = requests.get(url)\n",
                "# nombre_archivo = \"bank-marketing-campaign-data.csv\"\n",
                "# with open(nombre_archivo, 'wb') as archivo:\n",
                "#     archivo.write(respuesta.content)\n",
                "\n",
                "\n",
                "# 2. convertir csv en dataframe\n",
                "\n",
                "total_data = pd.read_csv(\"../data/raw/bank-marketing-campaign-data.csv\", sep=';')\n",
                "# total_data.shape\n",
                "# total_data.info()\n",
                "\n",
                "# buscar duplicados\n",
                "\n",
                "# total_data_sin = total_data.drop_duplicates()\n",
                "# total_data_sin.shape\n",
                "# print(total_data.columns)\n",
                "\n",
                "# Eliminar información obivamente irrelevante para el target\n",
                "# Lo mas logico seria eliminar las siguentes columnas: \n",
                "# tambien las columnas con alto numero de null: todas tienen el mismo numero entradas \n",
                "\n",
                "total_data.drop(['contact', 'month', 'day_of_week', 'duration', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'nr.employed'], axis = 1, inplace = True)\n",
                "total_data.shape\n",
                "total_data.info()\n",
                "print(total_data.head())\n",
                "\n",
                "# analisis de variable univariante : 8 variables categoricas y 3 variable numerica\n",
                "\n",
                "fig, axis = plt.subplots(2, 4, figsize = (15, 7))\n",
                "\n",
                "# Crear un histograma múltiple\n",
                "sns.histplot(ax = axis[0, 0], data = total_data, x = \"job\").set_xlim(-0.1, 1.1)\n",
                "sns.histplot(ax = axis[0, 1], data = total_data, x = \"marital\").set(ylabel = None)\n",
                "sns.histplot(ax = axis[0, 2], data = total_data, x = \"education\").set(ylabel = None)\n",
                "sns.histplot(ax = axis[0, 3], data = total_data, x = \"default\")\n",
                "sns.histplot(ax = axis[1, 0], data = total_data, x = \"housing\").set(ylabel = None)\n",
                "sns.histplot(ax = axis[1, 1], data = total_data, x = \"loan\").set(ylabel = None)\n",
                "sns.histplot(ax = axis[1, 2], data = total_data, x = \"poutcome\").set(ylabel = None)\n",
                "sns.histplot(ax = axis[1, 3], data = total_data, x = \"y\").set(ylabel = None)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Analisis univariable: \n",
                "\n",
                "job: la gran mayoria de los entrevistados trabaja en servicios\n",
                "\n",
                "marital: el numero de casados es mucho mayor que el de solteros y divorciados juntos\n",
                "\n",
                "default: sobre 3/4 partes delos entrevistados tienen credito\n",
                "\n",
                "housing: hay poca diferencia enre usuariuos con prestamo de vivienda y sin el\n",
                "\n",
                "loan: solo 1/7 de los clientes tienen un prestamo personal \n",
                "\n",
                "previous outcome: en la enorme mayoria de casos no habia registro del resultado de la campña anterior. ¿Nuevos clientes?\n",
                "\n",
                "target: aprox 1/7 de los clientes entrevistados aceptaron la oferta \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analisis de variables numericas:\n",
                "\n",
                "fig, axis = plt.subplots(2, 3, figsize = (10, 7), gridspec_kw={'height_ratios': [6, 1]})\n",
                "\n",
                "# Crear una figura múltiple con histogramas y diagramas de caja\n",
                "sns.histplot(ax = axis[0, 0], data = total_data, x = \"campaign\").set(xlabel = None)\n",
                "sns.boxplot(ax = axis[1, 0], data = total_data, x = \"campaign\")\n",
                "sns.histplot(ax = axis[0, 1], data = total_data, x = \"age\").set(xlabel = None, ylabel = None)\n",
                "sns.boxplot(ax = axis[1, 1], data = total_data, x = \"age\")\n",
                "sns.histplot(ax = axis[0, 2], data = total_data, x = \"euribor3m\").set(xlabel = None, ylabel = None)\n",
                "sns.boxplot(ax = axis[1, 2], data = total_data, x = \"euribor3m\")\n",
                "\n",
                "# Ajustar el layout\n",
                "plt.tight_layout()\n",
                "\n",
                "# Mostrar el plot\n",
                "plt.show()\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "La variable \"age\" tiene una distribucion asimetrica positiva y datos poco dispersos con sesgo hacia la derecha\n",
                "\n",
                "La variable \"campaign\" tiene muchos valores atipicos \n",
                "\n",
                "la variable \"euribor3m\" tiene los datos muy dispersos y con distribucion muy asimetrica negativa \n",
                "\n",
                "Ahora vamos a comparar la variable \"age\" y la \"euribor3m\" con la target \"y\"\n",
                "\n",
                "La variable target solo tiene respuestas yes/no asi que podemos convertirla en una variable numerica 1/0 \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# valores_unicos = total_data['loan'].unique().tolist()\n",
                "# print(valores_unicos)\n",
                "\n",
                "total_data['y_mapped'] = total_data['y'].map({'yes': 1, 'no': 0})\n",
                "# print(total_data.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axis = plt.subplots(2, 2, figsize = (10, 7))\n",
                "\n",
                "# Crear un diagrama de dispersión múltiple\n",
                "sns.regplot(ax = axis[0, 0], data = total_data, x = \"age\", y = \"y_mapped\")\n",
                "sns.heatmap(total_data[[\"age\", \"y_mapped\"]].corr(), annot = True, fmt = \".2f\", ax = axis[1, 0], cbar = False)\n",
                "sns.regplot(ax = axis[0, 1], data = total_data, x = \"euribor3m\", y = \"y_mapped\").set(ylabel=None)\n",
                "sns.heatmap(total_data[[\"y_mapped\", \"euribor3m\"]].corr(), annot = True, fmt = \".2f\", ax = axis[1, 1])\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "De aqui se puede observar que la variable \"age\" tiene incidencia positiva muy debil en el target, mientras que parece haber una relacion directa negativa entre la variable euribor3m y la contratacion del deposito (target). Es decir, a mayor euribor menos numero de contrato de depositos. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# analisis categorico-categorico\n",
                "\n",
                "fig, axis = plt.subplots(2, 3, figsize = (15, 7))\n",
                "\n",
                "sns.countplot(ax = axis[0, 0], data = total_data, x = \"job\", hue = \"y\")\n",
                "sns.countplot(ax = axis[0, 1], data = total_data, x = \"marital\", hue = \"y\").set(ylabel = None)\n",
                "sns.countplot(ax = axis[0, 2], data = total_data, x = \"loan\", hue = \"y\").set(ylabel = None)\n",
                "sns.countplot(ax = axis[1, 0], data = total_data, x = \"housing\", hue = \"y\")\n",
                "sns.countplot(ax = axis[1, 1], data = total_data, x = \"education\", hue = \"y\").set(ylabel = None)\n",
                "sns.countplot(ax = axis[1, 2], data = total_data, x = \"default\", hue = \"y\").set(ylabel = None)\n",
                "plt.tight_layout()\n",
                "fig.delaxes(axis[1, 2])\n",
                "plt.show()\n",
                "\n",
                "# valores unicos en education y job\n",
                "\n",
                "grados_edu = total_data['education'].unique().tolist()\n",
                "trabajos = total_data['job'].unique().tolist()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Del gráfico anterior podemos obtener las siguientes conclusiones:\n",
                "\n",
                "- mayor proporcion de solteros que de casados contrataron el deposito\n",
                "- la misma proporcion de clientes con y sin prestamos de hogar contrataron el deposito >>> no afecta \n",
                "- similar proporcion de clientes con y sin prestamos personales contrataron el deposito >>> no afecta\n",
                "- los grados de educacion son: ['basic.4y', 'high.school', 'basic.6y', 'basic.9y', 'professional.course', 'unknown', 'university.degree', 'illiterate'], asi que parece que la mayor proporcion de \"yes\" esta en \"university.degree\"\n",
                "- los diferentes trabajos son \"['housemaid', 'services', 'admin.', 'blue-collar', 'technician', 'retired', 'management', 'unemployed', 'self-employed', 'unknown', 'entrepreneur', 'student'], la mayor proporcion de contratos corresponde a \"student\"\n",
                "\n",
                "******Segun este analisis previo los valores con mas alta proporcion de contratacion de depositos son: student - university degree - single \n",
                "\n",
                "USamos factorize para para codificar una variable categórica como una matriz de etiquetas numéricas uy pode realizar el analisis de correlaciones necesitamos  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "total_data[\"job_n\"] = pd.factorize(total_data[\"job\"])[0]\n",
                "total_data[\"marital_n\"] = pd.factorize(total_data[\"marital\"])[0]\n",
                "total_data[\"education_n\"] = pd.factorize(total_data[\"education\"])[0]\n",
                "total_data[\"default_n\"] = pd.factorize(total_data[\"default\"])[0]\n",
                "total_data[\"housing_n\"] = pd.factorize(total_data[\"housing\"])[0]\n",
                "total_data[\"loan_n\"] = pd.factorize(total_data[\"loan\"])[0]\n",
                "\n",
                "\n",
                "fig, axis = plt.subplots(figsize = (10, 6))\n",
                "\n",
                "sns.heatmap(total_data[[\"job_n\", \"marital_n\", \"education_n\", \"default_n\", \"housing_n\", \"y_mapped\", \"euribor3m\", \"age\", \"campaign\" ]].corr(), annot = True, fmt = \".2f\")\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "ingenieria de caracteristicas: analisis descriptivo\n",
                " "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "total_data.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dibujar los diagramas de cajas de las variables \n",
                "\n",
                "fig, axis = plt.subplots(3, 3, figsize = (15, 10))\n",
                "\n",
                "sns.boxplot(ax = axis[0, 0], data = total_data, y = \"age\")\n",
                "sns.boxplot(ax = axis[0, 1], data = total_data, y = \"campaign\")\n",
                "sns.boxplot(ax = axis[0, 2], data = total_data, y = \"euribor3m\")\n",
                "sns.boxplot(ax = axis[1, 0], data = total_data, y = \"y_mapped\")\n",
                "sns.boxplot(ax = axis[1, 1], data = total_data, y = \"job_n\")\n",
                "sns.boxplot(ax = axis[1, 2], data = total_data, y = \"marital_n\")\n",
                "sns.boxplot(ax = axis[2, 0], data = total_data, y = \"education_n\")\n",
                "sns.boxplot(ax = axis[2, 1], data = total_data, y = \"default_n\")\n",
                "sns.boxplot(ax = axis[2, 2], data = total_data, y = \"housing_n\")\n",
                "\n",
                "\n",
                "plt.tight_layout()\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "las variables afectadas por los outliers son: default_n, age, job_n, campaing, \n",
                "Eliminamos: default_n, campaing,\n",
                "Revisamos: age, job_n, \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# revisando el numero de outliers\n",
                "\n",
                "age_stats = total_data[\"age\"].describe()\n",
                "age_stats\n",
                "\n",
                "age_iqr = age_stats[\"75%\"] - age_stats[\"25%\"]\n",
                "upper_limit = age_stats[\"75%\"] + 1.5 * age_iqr\n",
                "lower_limit = age_stats[\"25%\"] - 1.5 * age_iqr\n",
                "\n",
                "print(\"estos son los upper y lower limites de edad:\", upper_limit, \"y\", lower_limit)\n",
                "\n",
                "total_data_fil = total_data[(total_data[\"age\"] > 69.5)]\n",
                "total_data_fil2 = total_data[(total_data[\"age\"] < 9.5)]\n",
                "\n",
                "\n",
                "\n",
                "# no hay valores nulos\n",
                "\n",
                "total_data.isnull().sum().sort_values(ascending=False)\n",
                "\n",
                "total_data.shape\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Outliers: (age) Solo 481 valores sobrepasan el upper limite y 18 el lower limit: 1.1678% de los registros. \n",
                "- Análisis de valores faltantes: no hay valores nulos\n",
                "- SIGUIENTE PASO: Dividir el conjunto en train y test "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Dividir el conjunto en train y test \n",
                "# print(total_data.columns)\n",
                "\n",
                "total_data = total_data.drop(['job', 'marital', 'education', 'default', 'housing', 'loan', 'campaign', 'poutcome', 'y'], axis=1)\n",
                "\n",
                "total_data.shape\n",
                "\n",
                "X = total_data.drop(['y_mapped'], axis=1) # Características (features)\n",
                "y = total_data['y_mapped']  # Etiqueta (label)\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "X_train.head()\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# normalizacion escalar. \n",
                "\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "scaler = StandardScaler()\n",
                "scaler.fit(X_train)\n",
                "\n",
                "X_train_norm = scaler.transform(X_train)\n",
                "X_train_norm = pd.DataFrame(X_train_norm, index = X_train.index)\n",
                "\n",
                "X_test_norm = scaler.transform(X_test)\n",
                "X_test_norm = pd.DataFrame(X_test_norm, index = X_test.index)\n",
                "\n",
                "X_train_norm.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# feature selection\n",
                "\n",
                "from sklearn.feature_selection import f_classif, SelectKBest\n",
                "\n",
                "# Con un valor de k = 5 decimos implícitamente que queremos eliminar 2 características del conjunto de datos\n",
                "selection_model = SelectKBest(f_classif, k = 5)\n",
                "selection_model.fit(X_train, y_train)\n",
                "ix = selection_model.get_support()\n",
                "X_train_sel = pd.DataFrame(selection_model.transform(X_train), columns = X_train.columns.values[ix])\n",
                "X_test_sel = pd.DataFrame(selection_model.transform(X_test), columns = X_test.columns.values[ix])\n",
                "\n",
                "X_train_sel.head()\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Construye un modelo de regresión logística\n",
                "1. entrenamiento del modelo\n",
                "2. optimizacion del modelo \n",
                "\n",
                "test1 : The output indicates that your model is predicting all instances as the negative class (0), which is why you have high accuracy but precision, recall, and F1 score are all zero. This is typically a sign of class imbalance or a model that is not well-tuned for the positive class.\n",
                "\n",
                "test 2: añadido un parametro al modelo y otro a la metrica \"precision\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "\n",
                "model = LogisticRegression(class_weight='balanced') # añadido parametro para \n",
                "model.fit(X_train_sel, y_train)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "2. Prediccion del modelo "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred = model.predict(X_test_sel)\n",
                "y_pred\n",
                "y_pred.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "3. metricas: accuracy, precision, recall, F1 score \n",
                "\n",
                "- Accuracy: 71.67%\n",
                "- Precision: 24.25%\n",
                "- Recall: 70.48%\n",
                "- F1 Score: 36.09%\n",
                "- Confusion Matrix: [[5245, 2058], [276, 659]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
                "\n",
                "\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "accuracy_score(y_test, y_pred, normalize=False)\n",
                "\n",
                "precision = precision_score(y_test, y_pred, zero_division=0)  #añadido el parametro zero_division\n",
                "recall = recall_score(y_test, y_pred)\n",
                "f1 = f1_score(y_test, y_pred)\n",
                "conf_matrix = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "\n",
                "print(f'Accuracy: {accuracy}')\n",
                "print(f'Precision: {precision}')\n",
                "print(f'Recall: {recall}')\n",
                "print(f'F1 Score: {f1}')\n",
                "print(f'Confusion Matrix:\\n{conf_matrix}')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Graficar la  confusion_matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import confusion_matrix\n",
                "\n",
                "banking_cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "# Dibujaremos esta matriz para hacerla más visual\n",
                "bank_df = pd.DataFrame(banking_cm)\n",
                "\n",
                "plt.figure(figsize = (3, 3))\n",
                "sns.heatmap(bank_df, annot=True, fmt=\"d\", cbar=False)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
